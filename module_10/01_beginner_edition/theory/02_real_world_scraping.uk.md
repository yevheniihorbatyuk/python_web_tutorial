# Урок 2: Створення скрепера для реальних задач

## Вступ: Створення скреперів промислового рівня

Урок 1 охопив основи. Тепер ми створимо скрепер промислового рівня, який включає:
- Надійну обробку помилок і повторні спроби.
- Валідацію та очищення даних.
- Збереження в базу даних.
- Професійне логування.

## Повний робочий процес

Процес скрапінгу в реальному світі виглядає так:
1.  **Отримати дані** (з логікою повторних спроб для мережевих збоїв).
2.  **Розпарсити HTML** у структурований формат.
3.  **Видобути елементи** в моделі даних.
4.  **Валідувати дані** для забезпечення якості.
5.  **Перевірити на дублікати**, щоб уникнути зайвих записів.
6.  **Зберегти в базу даних** для постійного зберігання та запитів.
7.  **Логувати все** для моніторингу та налагодження.

---

## Частина 1: Ключові концепції для надійного скрапінгу

### Логіка повторних спроб (Exponential Backoff)

Мережі ненадійні. Коли запит не вдається, не варто відразу здаватися. **Exponential backoff** — це стратегія, за якою ви повторюєте невдалий запит з поступово довшими інтервалами очікування.

**Шаблон:**
- Спроба 1: Невдача. Зачекайте 1 секунду.
- Спроба 2: Невдача. Зачекайте 2 секунди.
- Спроба 3: Невдача. Зачекайте 4 секунди.

Це дає час для вирішення тимчасових проблем з мережею або сервером.

### Структуровані дані з Dataclasses

Замість звичайних словників використовуйте `dataclasses` Python для визначення чіткої структури ваших даних.

```python
from dataclasses import dataclass, field
from datetime import datetime

@dataclass
class Article:
    title: str
    url: str
    author: str
    scraped_at: str = field(default_factory=datetime.now().isoformat)
```
**Переваги:** підказки типів, значення за замовчуванням та самодокументований код.

### Логування (а не `print()`)

У продакшені `print()` недостатньо. Модуль `logging` надає:
- **Рівні важливості:** `INFO`, `WARNING`, `ERROR`.
- **Часові мітки:** знати, *коли* щось сталося.
- **Конфігурованість:** вивід у консоль, файли або зовнішні сервіси.

```python
import logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')

logging.info("Скрапінг розпочато.")
logging.error("Не вдалося завантажити сторінку.")
```

### Збереження в базу даних за допомогою SQLite

Для зберігання зібраних даних база даних є надійнішою, ніж простий файл. **SQLite** — це легка, файлова база даних, вбудована в Python.

**Ключові операції:**
- **`CREATE TABLE`**: визначення схеми (колонки та типи даних).
- **`INSERT`**: додавання нових записів.
- **Обмеження `UNIQUE`**: запобігання дублюванню записів на основі певного поля (наприклад, URL).

---
## Додаткові ресурси

- [Документація Python `dataclasses`](https://docs.python.org/3/library/dataclasses.html)
- [Посібник з `logging` в Python](https://docs.python.org/3/howto/logging.html)
- [Документація модуля `sqlite3` в Python](https://docs.python.org/3/library/sqlite3.html)
- [Requests: Розширене використання (повторні спроби)](https://requests.readthedocs.io/en/latest/user/advanced/)
